{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import edgetpu.conversion_tf as conv\n",
    "from hummingbird.ml import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([5, 5, 5, 5, 5, 5, 5, 5], shape=[1,8])\n",
    "y = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.constant([[1, 1, 1], [2, 2, 2], [3, 3, 3]], shape=[3,3])\n",
    "B = tf.constant([[1, 2, 3], [1, 2, 3], [1, 2, 3]], shape=[3,3])\n",
    "\n",
    "A_t = torch.tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "B_t = torch.tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [4, 4, 4],\n",
       "       [9, 9, 9]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(A_t, tf.transpose(B_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [4, 4, 4],\n",
       "       [9, 9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(A, tf.transpose(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=bool, numpy=\n",
       "array([[ True,  True,  True],\n",
       "       [False,  True,  True],\n",
       "       [False, False,  True]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.less_equal(A, B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = tf.constant([[1, 1], [2, 2], [3, 3]], shape=[3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,0): 6\n",
      "(0,1): 6\n",
      "(1,0): 12\n",
      "(1,1): 12\n",
      "(2,0): 18\n",
      "(2,1): 18\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(A):\n",
    "    for j, col in enumerate(tf.transpose(C)):\n",
    "        added = tf.multiply(row, col)\n",
    "        val = tf.reduce_sum(added)\n",
    "        print(f'({i},{j}): {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 11:27:27.005487: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-20 11:27:27.005606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (XPS-9500): /proc/driver/nvidia/version does not exist\n",
      "2023-03-20 11:27:27.013078: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data = np.random.uniform(low=0., high=8., size=(1,8))\n",
    "      yield [data.astype(np.float32)]\n",
    " \n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=105)\n",
    "X, y = make_classification(n_samples=1300, n_features=8,\n",
    "                           n_informative=4, n_redundant=1,\n",
    "                           random_state=0, shuffle=True,\n",
    "                           n_classes=4)\n",
    "\n",
    "x_train, y_train = X[:1000], y[:1000]\n",
    "x_test, y_test = X[1000:], y[1000:]\n",
    "\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "X = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1, 8], dtype=tf.int32)\n",
    "X_float = tf.constant([1., 2., 3., 4., 5., 6., 7., 8.], shape=[1, 8])\n",
    "X_8 = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1, 8], dtype=tf.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = convert(forest, 'torch', extra_config={\"tree_implementation\":\"gemm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = conv_model.model._operators[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_gemm \u001b[39m=\u001b[39m conv\u001b[39m.\u001b[39mGEMMDecisionTreeImpl(forest)\n\u001b[1;32m      3\u001b[0m y_mod_pred_gemm, y_mod_gemm \u001b[39m=\u001b[39m conv_model\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m_operators[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mforward((torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1.\u001b[39m, \u001b[39m2.\u001b[39m, \u001b[39m3.\u001b[39m, \u001b[39m4.\u001b[39m, \u001b[39m5.\u001b[39m, \u001b[39m6.\u001b[39m, \u001b[39m7.\u001b[39m, \u001b[39m8.\u001b[39m]])))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forest' is not defined"
     ]
    }
   ],
   "source": [
    "model_gemm = conv.GEMMDecisionTreeImpl(forest)\n",
    "\n",
    "y_mod_pred_gemm, y_mod_gemm = conv_model.model._operators[0].forward((torch.tensor([[1., 2., 3., 4., 5., 6., 7., 8.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2952, 0.4190, 0.0286, 0.2571]], grad_fn=<TBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mod_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gemm, y_gemm = model_gemm(X_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.2952381 , 0.41904762, 0.02857143, 0.25714287]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=uint8, numpy=array([[0, 0, 0, 0]], dtype=uint8)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(y_gemm / 100, tf.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing casted __call__ run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.transpose(tf.constant([[1,2,3,4,5,6,7,8]], dtype=tf.int8))\n",
    "xf = tf.transpose(tf.constant([[1.,2.,3.,4.,5.,6.,7.,8.]], dtype=tf.float32))\n",
    "w1 = tf.cast(op.weight_1.detach(), tf.int8) \n",
    "b1 = tf.cast(op.bias_1.detach() * 10, tf.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.less_equal(np.matmul(w1, x) * 10, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = tf.less_equal(tf.linalg.matmul(op.weight_1.detach(), xf), op.bias_1.detach())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By mulitplying both sides by 10 we prevent values like 0.2 to lose their information by being rounded to 0 .This way we managed to make the comparisons equivalent but its now int32 based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(21525, 1), dtype=bool, numpy=\n",
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.cast(x, tf.uint8)\n",
    "xf = tf.cast(xf, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(21525, 8), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.less_equal(w1 * 10, b1) == tf.math.less_equal(op.weight_1.detach(), op.bias_1.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(x, (op.n_trees, op.hidden_one_size, -1))\n",
    "xf = tf.reshape(xf, (op.n_trees, op.hidden_one_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(105, 206, 1), dtype=bool, numpy=\n",
       "array([[[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = tf.cast(op.weight_2.detach(), tf.uint8)\n",
    "x = np.matmul(w2, x)\n",
    "xf = tf.linalg.matmul(op.weight_2.detach(), xf)\n",
    "x == tf.cast(xf, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(x, (op.n_trees * op.hidden_two_size, -1)) == tf.cast(op.bias_2.detach(), tf.uint8)\n",
    "xf = tf.reshape(xf, (op.n_trees * op.hidden_two_size, -1)) == op.bias_2.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(x, (op.n_trees, op.hidden_two_size, -1))\n",
    "xf = tf.reshape(xf, (op.n_trees, op.hidden_two_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.cast(x, dtype=tf.uint8)\n",
    "xf = tf.cast(xf, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(105, 206, 1), dtype=bool, numpy=\n",
       "array([[[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == tf.cast(xf, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(105, 4, 206), dtype=uint8, numpy=\n",
       "array([[[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [95,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0, 95, 95, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0, 95, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [95,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0, 95,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [95,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0, 95, ...,  0,  0,  0],\n",
       "        [ 0, 95,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[95, 95,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0, 95, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [95,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0, 95, 95, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 0, 95,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0, 95, ...,  0,  0,  0],\n",
       "        [95,  0,  0, ...,  0,  0,  0]]], dtype=uint8)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(op.weight_3.detach() * 10000, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_func = model_gemm.__call__.get_concrete_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func], model_gemm)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  \n",
    "converter.inference_output_type = tf.int8\n",
    "converter.allow_custom_ops = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpire21tpy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 19:33:16.493767: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-02-07 19:33:16.493830: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-02-07 19:33:16.494038: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpire21tpy\n",
      "2023-02-07 19:33:16.507849: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-07 19:33:16.507891: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpire21tpy\n",
      "2023-02-07 19:33:16.560733: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-02-07 19:33:16.647107: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpire21tpy\n",
      "2023-02-07 19:33:16.738874: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 244840 microseconds.\n",
      "2023-02-07 19:33:17.097993: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 9.386 M  ops, equivalently 4.693 M  MACs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 9.386 M  ops, equivalently 4.693 M  MACs\n",
      "Estimated count of arithmetic ops: 9.386 M  ops, equivalently 4.693 M  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "2023-02-07 19:33:18.307182: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 9.386 M  ops, equivalently 4.693 M  MACs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tflite_model_gemm = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_gemm)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "output = interpreter.get_output_details()[0]  \n",
    "input = interpreter.get_input_details()[0]  \n",
    "\n",
    "\n",
    "interpreter.set_tensor(input['index'], X_8)\n",
    "interpreter.invoke()\n",
    "y_lite_gemm = interpreter.get_tensor(output['index'])\n",
    "\n",
    "y_pred_lite_gemm = np.argmax(y_lite_gemm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 98,  94, 123,  92]], dtype=int8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lite_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../saved_models/random_forest/int32/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_gemm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current stats\n",
    "### GEMM model\n",
    "name | value |\n",
    "|:---------|:---------|\n",
    "Input model| model.tflite \n",
    "Input size | 4.87MiB \n",
    "Output model | model_edgetpu.tflite \n",
    "Output size | 19.75MiB \n",
    "On-chip memory used for caching model parameters | 7.62MiB \n",
    "On-chip memory remaining for caching model parameters | 259.75KiB \n",
    "Off-chip memory used for streaming uncached model parameters | 9.74MiB \n",
    "Number of Edge TPU subgraphs | 1 \n",
    "Total number of operations | 437 \n",
    "Number of operations that will run on Edge TPU | 212 \n",
    "Number of operations that will run on CPU | 225 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bachelorarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcf7a5713a516aa2d3421acea07eb3b3e608abd40c4052e069e1a6582ee3f7b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
