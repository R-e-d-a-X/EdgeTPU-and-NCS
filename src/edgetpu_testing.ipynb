{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 11:53:03.237768: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from conversion_tf import GEMMDecisionTreeImplEdgeTPU, GEMMDecisionTreeImpl, TreeTraversalDecisionTreeImpl\n",
    "from hummingbird.ml import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 11:53:08.821625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 11:53:08.822836: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([5, 5, 5, 5, 5, 5, 5, 5], shape=[1,8])\n",
    "y = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data = np.random.uniform(low=0., high=10., size=(1, 8))\n",
    "      yield [data.astype(np.float32)]\n",
    " \n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "X, y = make_classification(n_samples=1300, n_features=8,\n",
    "                           n_informative=4, n_redundant=1,\n",
    "                           random_state=0, shuffle=True,\n",
    "                           n_classes=4)\n",
    "\n",
    "x_train, y_train = X[:1000], y[:1000]\n",
    "x_test, y_test = X[1000:], y[1000:]\n",
    "\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "X = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1, 8], dtype=tf.int32)\n",
    "X_float = tf.constant([1., 2., 3., 4., 5., 6., 7., 8.], shape=[1, 8])\n",
    "X_8 = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1, 8], dtype=tf.int8)\n",
    "x_300 = np.random.randint(low=0, high=10, size=(300, 8)).astype(np.int8)\n",
    "x_300_f = x_300.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = convert(forest, 'torch', extra_config={\"tree_implementation\":\"gemm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = conv_model.model._operators[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gemm = GEMMDecisionTreeImpl(forest)\n",
    "\n",
    "y_mod_pred_gemm, y_mod_gemm = conv_model.model._operators[0].forward((torch.tensor([[1., 2., 3., 4., 5., 6., 7., 8.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2773, 0.4007, 0.0411, 0.2809]], grad_fn=<TBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mod_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gemm = model_gemm(X_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.27728087, 0.40071556, 0.0411449 , 0.28085867]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1]), tensor([[0.2773, 0.4007, 0.0411, 0.2809]], grad_fn=<TBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.model._operators[0].forward((torch.tensor([[5., 5., 1., 2., 1., 8., 7., 3.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_func = model_gemm.__call__.get_concrete_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func], model_gemm)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  \n",
    "converter.inference_output_type = tf.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpl72a04mm/assets\n",
      "Estimated count of arithmetic ops: 36  ops, equivalently 18  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 11:54:11.089912: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-02-22 11:54:11.089943: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-02-22 11:54:11.090706: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpl72a04mm\n",
      "2023-02-22 11:54:11.091086: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-22 11:54:11.091108: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpl72a04mm\n",
      "2023-02-22 11:54:11.091309: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-02-22 11:54:11.092082: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-02-22 11:54:11.092703: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-02-22 11:54:11.129592: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpl72a04mm\n",
      "2023-02-22 11:54:11.131862: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 41161 microseconds.\n",
      "2023-02-22 11:54:11.159354: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-22 11:54:11.181363: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-02-22 11:54:11.261136: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 36  ops, equivalently 18  MACs\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tensorflow/lite/kernels/fully_connected.cc:228 NumDimensions(filter) != 2 (4 != 2)Node number 0 (FULLY_CONNECTED) failed to prepare.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tflite_model_gemm \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mconvert()\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1863\u001b[0m, in \u001b[0;36mTFLiteConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1851\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Converts a TensorFlow GraphDef based on instance variables.\u001b[39;00m\n\u001b[1;32m   1852\u001b[0m \n\u001b[1;32m   1853\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[39m      Invalid quantization parameters.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1863\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TFLiteConverterV2, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mconvert()\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:930\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(convert_func)\n\u001b[1;32m    928\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    929\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 930\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_and_export_metrics(convert_func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:908\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m    907\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[0;32m--> 908\u001b[0m result \u001b[39m=\u001b[39m convert_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    909\u001b[0m elapsed_time_ms \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m start_time) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m    910\u001b[0m \u001b[39mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1502\u001b[0m, in \u001b[0;36mTFLiteFrozenGraphConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Converts a TensorFlow GraphDef based on instance variables.\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \n\u001b[1;32m   1491\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[39m    Invalid quantization parameters.\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_lower_to_saved_model:\n\u001b[0;32m-> 1502\u001b[0m   saved_model_convert_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_as_saved_model()\n\u001b[1;32m   1503\u001b[0m   \u001b[39mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1504\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1482\u001b[0m, in \u001b[0;36mTFLiteFrozenGraphConverterV2._convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msaved_model_dir:\n\u001b[1;32m   1481\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(graph_def, input_tensors)\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_from_saved_model(graph_def)\n\u001b[1;32m   1483\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1484\u001b[0m   shutil\u001b[39m.\u001b[39mrmtree(temp_dir, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:1097\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2._convert_from_saved_model\u001b[0;34m(self, graph_def)\u001b[0m\n\u001b[1;32m   1094\u001b[0m converter_kwargs\u001b[39m.\u001b[39mupdate(quant_mode\u001b[39m.\u001b[39mconverter_flags())\n\u001b[1;32m   1096\u001b[0m result \u001b[39m=\u001b[39m _convert_saved_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconverter_kwargs)\n\u001b[0;32m-> 1097\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimize_tflite_model(\n\u001b[1;32m   1098\u001b[0m     result, quant_mode, quant_io\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperimental_new_quantizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n\u001b[0;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:868\u001b[0m, in \u001b[0;36mTFLiteConverterBase._optimize_tflite_model\u001b[0;34m(self, model, quant_mode, quant_io)\u001b[0m\n\u001b[1;32m    866\u001b[0m   q_bias_type \u001b[39m=\u001b[39m quant_mode\u001b[39m.\u001b[39mbias_type()\n\u001b[1;32m    867\u001b[0m   q_allow_float \u001b[39m=\u001b[39m quant_mode\u001b[39m.\u001b[39mis_allow_float()\n\u001b[0;32m--> 868\u001b[0m   model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_quantize(model, q_in_type, q_out_type, q_activations_type,\n\u001b[1;32m    869\u001b[0m                          q_bias_type, q_allow_float)\n\u001b[1;32m    871\u001b[0m m_in_type \u001b[39m=\u001b[39m in_type \u001b[39mif\u001b[39;00m in_type \u001b[39melse\u001b[39;00m _dtypes\u001b[39m.\u001b[39mfloat32\n\u001b[1;32m    872\u001b[0m m_out_type \u001b[39m=\u001b[39m out_type \u001b[39mif\u001b[39;00m out_type \u001b[39melse\u001b[39;00m _dtypes\u001b[39m.\u001b[39mfloat32\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:612\u001b[0m, in \u001b[0;36mTFLiteConverterBase._quantize\u001b[0;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float)\u001b[0m\n\u001b[1;32m    608\u001b[0m calibrate_quantize \u001b[39m=\u001b[39m _calibrator\u001b[39m.\u001b[39mCalibrator(result,\n\u001b[1;32m    609\u001b[0m                                             custom_op_registerers_by_name,\n\u001b[1;32m    610\u001b[0m                                             custom_op_registerers_by_func)\n\u001b[1;32m    611\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_calibrate_only \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_new_quantizer:\n\u001b[0;32m--> 612\u001b[0m   calibrated \u001b[39m=\u001b[39m calibrate_quantize\u001b[39m.\u001b[39;49mcalibrate(\n\u001b[1;32m    613\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentative_dataset\u001b[39m.\u001b[39;49minput_gen)\n\u001b[1;32m    615\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_calibrate_only:\n\u001b[1;32m    616\u001b[0m   \u001b[39mreturn\u001b[39;00m calibrated\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n\u001b[0;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/optimize/calibrator.py:226\u001b[0m, in \u001b[0;36mCalibrator.calibrate\u001b[0;34m(self, dataset_gen)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m@convert_phase\u001b[39m(Component\u001b[39m.\u001b[39mOPTIMIZE_TFLITE_MODEL, SubComponent\u001b[39m.\u001b[39mCALIBRATE)\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalibrate\u001b[39m(\u001b[39mself\u001b[39m, dataset_gen):\n\u001b[1;32m    218\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calibrates the model with specified generator.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m    dataset_gen: A generator that generates calibration samples.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed_tensors(dataset_gen, resize_input\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    227\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calibrator\u001b[39m.\u001b[39mCalibrate()\n",
      "File \u001b[0;32m~/anaconda3/envs/BA2/lib/python3.8/site-packages/tensorflow/lite/python/optimize/calibrator.py:129\u001b[0m, in \u001b[0;36mCalibrator._feed_tensors\u001b[0;34m(self, dataset_gen, resize_input)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calibrator\u001b[39m.\u001b[39mPrepare([\u001b[39mlist\u001b[39m(s\u001b[39m.\u001b[39mshape) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m input_array],\n\u001b[1;32m    127\u001b[0m                              signature_key)\n\u001b[1;32m    128\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calibrator\u001b[39m.\u001b[39;49mPrepare([\u001b[39mlist\u001b[39;49m(s\u001b[39m.\u001b[39;49mshape) \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m input_array])\n\u001b[1;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m   \u001b[39mif\u001b[39;00m signature_key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tensorflow/lite/kernels/fully_connected.cc:228 NumDimensions(filter) != 2 (4 != 2)Node number 0 (FULLY_CONNECTED) failed to prepare."
     ]
    }
   ],
   "source": [
    "tflite_model_gemm = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_gemm)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "output = interpreter.get_output_details()[0]  \n",
    "input = interpreter.get_input_details()[0]  \n",
    "\n",
    "interpreter.set_tensor(input['index'], X_8)\n",
    "interpreter.invoke()\n",
    "y_lite_gemm = interpreter.get_tensor(output['index'])\n",
    "\n",
    "y_pred_lite_gemm = np.argmax(y_lite_gemm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.39200002, 0.42400002, 0.008     , 0.17600001]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85,  74, 125, 103]], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lite_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lite_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../saved_models/random_forest/gemm/float32/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_gemm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current stats\n",
    "### GEMM model Edge TPU\n",
    "name | value |\n",
    "|:---------|:---------|\n",
    "Input model| model.tflite \n",
    "Input size | 4.54MiB \n",
    "Output model | model_edgetpu.tflite \n",
    "Output size | 20.48MiB \n",
    "On-chip memory used for caching model parameters | 7.67MiB \n",
    "On-chip memory remaining for caching model parameters | 34.25KiB \n",
    "Off-chip memory used for streaming uncached model parameters | 9.37MiB \n",
    "Number of Edge TPU subgraphs | 4 \n",
    "Total number of operations | 437 \n",
    "Number of operations that will run on Edge TPU | 427 \n",
    "Number of operations that will run on CPU | 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5b96343b31861d80b9d3de750e5a5e11a0f674dbcb91b0b966fee3e7b7f3d0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
