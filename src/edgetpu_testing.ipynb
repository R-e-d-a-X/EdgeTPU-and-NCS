{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 23:15:23.404690: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from conversion_tf import GEMMDecisionTreeImpl\n",
    "from hummingbird.ml import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "N_FEATURES = 4\n",
    "N_TREES = 1\n",
    "MAX_DEPTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 23:15:25.584325: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 23:15:25.584978: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([5, 5, 5, 5, 5, 5, 5, 5], shape=[1,8])\n",
    "y = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=N_TREES, max_depth=MAX_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=1, n_estimators=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=1, n_estimators=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=1, n_estimators=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data = np.random.uniform(low=0., high=10., size=(BATCH_SIZE, N_FEATURES))\n",
    "      yield [data.astype(np.float32)]\n",
    " \n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "X, y = make_classification(n_samples=1300, n_features=N_FEATURES,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=True,\n",
    "                           n_classes=2)\n",
    "\n",
    "x_train, y_train = X[:1000], y[:1000]\n",
    "x_test, y_test = X[1000:], y[1000:]\n",
    "\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 features\n",
    "X_2 = tf.constant([1, 2], shape=[1, 2], dtype=tf.int8)\n",
    "X_2_f = tf.cast(X_2, tf.float32)\n",
    "\n",
    "X_f_b = np.random.randint(low=0, high=10, size=(BATCH_SIZE, N_FEATURES)).astype(np.int8)\n",
    "X_f_b_f = X_f_b.astype(np.float32)\n",
    "\n",
    "# 8 features\n",
    "X = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1, 8], dtype=tf.int32)\n",
    "X_float = tf.constant([1., 2., 3., 4., 5., 6., 7., 8.], shape=[1, 8])\n",
    "X_8 = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=[1, 8], dtype=tf.int8)\n",
    "\n",
    "X_300 = np.random.randint(low=0, high=10, size=(300, 8)).astype(np.int8)\n",
    "X_300_f = X_300.astype(np.float32)\n",
    "\n",
    "X_1k_f = np.random.randint(low=0, high=10, size=(1000, 8)).astype(np.float32)\n",
    "X_1k = X_1k_f.astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = convert(forest, 'torch', extra_config={\"tree_implementation\":\"gemm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = conv_model.model._operators[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gemm = GEMMDecisionTreeImpl(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gemm = model_gemm(X_f_b_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512, 2), dtype=float32, numpy=\n",
       "array([[0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       ...,\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_func = model_gemm.__call__.get_concrete_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func], model_gemm)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  \n",
    "converter.inference_output_type = tf.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbjd043fn/assets\n",
      "Estimated count of arithmetic ops: 0.044 M  ops, equivalently 0.022 M  MACs\n",
      "Estimated count of arithmetic ops: 0.044 M  ops, equivalently 0.022 M  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 23:15:26.575350: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-06 23:15:26.575371: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-06 23:15:26.575862: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpbjd043fn\n",
      "2023-03-06 23:15:26.576118: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-06 23:15:26.576129: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpbjd043fn\n",
      "2023-03-06 23:15:26.576263: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-03-06 23:15:26.576769: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-03-06 23:15:26.576972: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-06 23:15:26.579986: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpbjd043fn\n",
      "2023-03-06 23:15:26.582019: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 6162 microseconds.\n",
      "2023-03-06 23:15:26.587218: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-06 23:15:26.588710: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-03-06 23:15:26.601088: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 0.044 M  ops, equivalently 0.022 M  MACs\n",
      "\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "2023-03-06 23:15:26.615801: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 0.044 M  ops, equivalently 0.022 M  MACs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tflite_model_gemm = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_gemm)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "output = interpreter.get_output_details()[0]  \n",
    "input = interpreter.get_input_details()[0]  \n",
    "\n",
    "interpreter.set_tensor(input['index'], X_f_b)\n",
    "interpreter.invoke()\n",
    "y_lite_gemm = interpreter.get_tensor(output['index'])\n",
    "\n",
    "y_pred_lite_gemm = np.argmax(y_lite_gemm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512, 2), dtype=float32, numpy=\n",
       "array([[0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       ...,\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ],\n",
       "       [0.13651878, 0.8634812 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-87, 127],\n",
       "       [-87, 127],\n",
       "       [-87, 127],\n",
       "       ...,\n",
       "       [-87, 127],\n",
       "       [-87, 127],\n",
       "       [-87, 127]], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lite_gemm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming model_abcd\n",
    "a = number of trees <br>\n",
    "b = max_depth <br>\n",
    "c = #features <br>\n",
    "d = batch size <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../saved_models/random_forest/gemm/float32/final_eval/model_{N_TREES}_{MAX_DEPTH}_{N_FEATURES}_{BATCH_SIZE}.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_gemm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current stats\n",
    "### GEMM model Edge TPU\n",
    "name | value |\n",
    "|:---------|:---------|\n",
    "Input model| model.tflite \n",
    "Input size | 4.54MiB \n",
    "Output model | model_edgetpu.tflite \n",
    "Output size | 20.48MiB \n",
    "On-chip memory used for caching model parameters | 7.67MiB \n",
    "On-chip memory remaining for caching model parameters | 34.25KiB \n",
    "Off-chip memory used for streaming uncached model parameters | 9.37MiB \n",
    "Number of Edge TPU subgraphs | 4 \n",
    "Total number of operations | 437 \n",
    "Number of operations that will run on Edge TPU | 427 \n",
    "Number of operations that will run on CPU | 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5b96343b31861d80b9d3de750e5a5e11a0f674dbcb91b0b966fee3e7b7f3d0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
