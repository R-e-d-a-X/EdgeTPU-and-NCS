EDGETPU:
Vermutete Verlustquellen:
    1. Wenn man ein Model kompiliert, dann wird nicht der ganze Edge TPU cache verwendet, 
    sondern Daten werden aus externem Speicher gestreamed, obwohl noch genug Platz On-Chip ist. 
    BSP: model_tensor_attr
    On-chip memory used for caching model parameters: 768.00B
    On-chip memory remaining for caching model parameters: 8.09MiB
    Off-chip memory used for streaming uncached model parameters: 128.00B

    2. Kommunikation zwischen TPU und CPU bei nicht kompatiblen Operationen

    3. Mögliches unnötiges Kopieren von Tensoren 


Verbesserungs Ideen:
    1. Dafür sorgen, dass alle Model-Parameter auf der TPU gecached werden können, 
    um externe Speicherzugriffe zu minimieren.


Beobachtungen:
    1. Multibatch scheint auf der Edge TPU besser zu skalieren. 
    Beim erhöhen der Batchsize von 1 auf 1000 verlangsamt sich die Inferenz bei der Edge TPU 
    um Faktor 4 und bei der CPU um Faktor 6.66, allerdings ist die CPU immer noch deutlich schneller.

    2. Die Varianz der Inferenzzeiten ist höher auf der Edge TPU als auf der CPU. 
    Minimum und Maximum Inferenzzeit weichen deutlich weiter vom Durchschnitt ab als bei der CPU.

    3. Hinzunahme von Operationen auf der Edge TPU kann die Inferenzzeit verringern. 
    Bspw dauert die Inferenz mit genau einer Transpose operation im Durchschnitt etwa 
    180mys länger als die Inferenz von 1 Transpose und 1 Matmul.

    4. Die Prediction des Models unterscheidet sich, wenn man es auf TPU oder CPU ausführt.


NCS2:
    mo nur benutzen, wenn OpenVINO environment noch nicht initialisiert ist
    less_equal nicht kompatibel, aber less und equal schon
    Wenn source setup.sh ausgeführt wird, funktionert Inferenz auf dem NCS2

    Das CPU-Plugin hat mehr Optimisierungsparamter als das MYRIAD Plugin, kann daher besser vom
    Benchmarkingtool optimisiert werden. 

    Mögliches TODO:
        > PTT auf NCS2 ausprobieren
        > NCS2 Benchmarks mit skalierender Modellgröße



